#!/usr/bin/env python3
from __future__ import annotations

import argparse
import json
from pathlib import Path
from typing import Any, Dict, List, Tuple

import requests


def analyze(base_url: str, text: str, timeout: float) -> Dict[str, Any]:
    url = base_url.rstrip("/") + "/api/analyze"
    r = requests.post(url, json={"text": text}, timeout=timeout)
    if r.status_code != 200:
        raise RuntimeError(f"POST {url} failed: {r.status_code} {r.text[:500]}")
    return r.json()


def load_cases(path: Path) -> Dict[str, Any]:
    if not path.exists():
        return {"version": "0.2", "notes": "autogenerated", "cases": []}
    return json.loads(path.read_text(encoding="utf-8"))


def save_cases(path: Path, data: Dict[str, Any]) -> None:
    path.write_text(json.dumps(data, ensure_ascii=False, indent=2) + "\n", encoding="utf-8")


def make_case_id(prefix: str, source_id: str) -> str:
    safe = source_id.replace(" ", "_").replace("-", "_")
    return f"{prefix}_{safe}"


def expected_from_curated(cur: Dict[str, Any], api_resp: Dict[str, Any]) -> Dict[str, Any]:
    """
    Create tolerant expectations that still catch regressions.
    We DON'T hardcode spans; we assert high-level behavior.
    """
    label = cur.get("label")
    items = api_resp.get("items") if isinstance(api_resp.get("items"), list) else []
    copy_allowed = bool(api_resp.get("copy_allowed")) if isinstance(api_resp.get("copy_allowed"), bool) else True
    is_clean = bool(api_resp.get("is_clean")) if isinstance(api_resp.get("is_clean"), bool) else False

    if label == "clean":
        return {"is_clean": True, "min_items": 0, "copy_allowed": True}

    # problematic
    sev = cur.get("severity")
    typ = cur.get("type")
    target = cur.get("target_substring")

    exp: Dict[str, Any] = {"is_clean": False, "min_items": 1, "copy_allowed": copy_allowed}

    if isinstance(sev, str) and sev in ("block", "warn", "info"):
        exp["must_have_severity"] = [sev]

    if isinstance(typ, str) and typ in ("slur", "stereotype", "exclusion", "hate", "other"):
        exp["must_have_type_any_of"] = [typ]

    if isinstance(target, str) and target.strip():
        exp["must_contain_original"] = [target.strip()]

    # If API is currently blocking copy, assert that as well (important UX)
    if copy_allowed is False:
        exp["copy_allowed"] = False

    # Safety: if API says clean but we are promoting, this shouldn't happen; handled elsewhere.
    return exp


def is_green_promotion(cur: Dict[str, Any], api_resp: Dict[str, Any]) -> bool:
    """
    Only promote to golden if current system already behaves as expected:
    - curated says clean -> api is_clean must be True
    - curated says problematic -> api is_clean must be False (has at least 1 item)
    """
    label = cur.get("label")
    is_clean = api_resp.get("is_clean")
    items = api_resp.get("items")
    if label == "clean":
        return is_clean is True and isinstance(items, list) and len(items) == 0
    # problematic
    return is_clean is False and isinstance(items, list) and len(items) >= 1


def main() -> int:
    ap = argparse.ArgumentParser(description="Promote curated candidates into golden tests (fully automated)")
    ap.add_argument("--base-url", default="http://localhost:8000", help="API base URL")
    ap.add_argument("--in", dest="inp", default="tests/candidates_curated.jsonl", help="Curated JSONL input")
    ap.add_argument("--cases", default="tests/cases.json", help="Golden cases.json path")
    ap.add_argument("--timeout", type=float, default=30.0, help="HTTP timeout")
    ap.add_argument("--max", type=int, default=5000, help="Max accepted records to consider")
    args = ap.parse_args()

    inp = Path(args.inp)
    cases_path = Path(args.cases)
    backlog_gaps = Path("tests/backlog_gaps.jsonl")
    backlog_fp = Path("tests/backlog_false_positives.jsonl")

    data = load_cases(cases_path)
    cases: List[Dict[str, Any]] = data.get("cases", [])
    existing_ids = {c.get("id") for c in cases if isinstance(c, dict)}

    promoted = 0
    gaps = 0
    fps = 0
    skipped = 0

    with inp.open("r", encoding="utf-8") as fin, \
         backlog_gaps.open("a", encoding="utf-8") as fg, \
         backlog_fp.open("a", encoding="utf-8") as ff:

        for line in fin:
            if promoted + gaps + fps + skipped >= args.max:
                break
            rec = json.loads(line)
            if not rec.get("accepted"):
                continue

            text = rec.get("text")
            cur = rec.get("curation", {})
            if not isinstance(text, str) or not text.strip() or not isinstance(cur, dict):
                continue

            api_resp = analyze(args.base_url, text, args.timeout)

            # Decide bucket
            if is_green_promotion(cur, api_resp):
                cid = make_case_id("auto", rec.get("id", "unknown"))
                if cid in existing_ids:
                    skipped += 1
                    continue

                case = {
                    "id": cid,
                    "text": text,
                    "expected": expected_from_curated(cur, api_resp),
                    "meta": {
                        "source": "llm_autopipeline",
                        "category": rec.get("category"),
                        "label": cur.get("label"),
                        "type": cur.get("type"),
                        "severity": cur.get("severity"),
                        "confidence": cur.get("confidence"),
                        "false_positive_risk": cur.get("false_positive_risk"),
                    },
                }
                cases.append(case)
                existing_ids.add(cid)
                promoted += 1
            else:
                # Not green: store in backlog files
                label = cur.get("label")
                if label == "problematic" and api_resp.get("is_clean") is True:
                    fg.write(json.dumps({"candidate": rec, "api": api_resp}, ensure_ascii=False) + "\n")
                    gaps += 1
                elif label == "clean" and api_resp.get("is_clean") is False:
                    ff.write(json.dumps({"candidate": rec, "api": api_resp}, ensure_ascii=False) + "\n")
                    fps += 1
                else:
                    skipped += 1

    data["cases"] = cases
    save_cases(cases_path, data)

    print(f"Promoted into {cases_path}: {promoted}")
    print(f"Gaps backlog (LLM says problematic, API clean): {gaps} -> {backlog_gaps}")
    print(f"False-positive backlog (LLM says clean, API flags): {fps} -> {backlog_fp}")
    print(f"Skipped/other: {skipped}")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())